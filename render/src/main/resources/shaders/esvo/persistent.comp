#version 430 core

layout(local_size_x = 32, local_size_y = 1, local_size_z = 1) in;

// Work item types
#define WORK_RAY_TRAVERSAL     0
#define WORK_SHADOW_RAY        1
#define WORK_AMBIENT_OCCLUSION 2
#define WORK_BEAM_TRAVERSAL    3

// Work item structure (32 bytes)
struct WorkItem {
    uint type;           // Work type
    uint dataLength;     // Length of data array
    float data[6];       // Work data (24 bytes)
};

// Work queue structure
struct WorkQueue {
    uint maxItems;       // Maximum work items
    uint itemSize;       // Size of each work item
    uint padding1;       // Alignment
    uint padding2;       // Alignment
    WorkItem items[];    // Work items array
};

// Queue counters
struct QueueCounters {
    uint head;           // Queue head index
    uint tail;           // Queue tail index  
    uint currentSize;    // Current queue size
    uint overflowCount;  // Number of overflows
};

// Buffers
layout(std430, binding = 0) buffer WorkQueueBuffer {
    WorkQueue workQueue;
} workQueueBuffer;

layout(std430, binding = 1) buffer CounterBuffer {
    QueueCounters counters;
} counterBuffer;

// Import traversal functions from other shaders
// These would be included or linked

// Shared memory for workgroup coordination
shared uint sharedWorkIndex[32];
shared bool sharedWorkAvailable;
shared uint sharedWorkCount;

// Thread-local variables
uint threadId = gl_LocalInvocationID.x;
uint blockId = gl_WorkGroupID.x;
uint globalThreadId = gl_GlobalInvocationID.x;

// Atomic operations for work queue
uint atomicDequeue() {
    uint head = atomicAdd(counterBuffer.counters.head, 1);
    uint maxItems = workQueueBuffer.workQueue.maxItems;
    
    if (head >= maxItems) {
        // Wrap around
        uint wrappedHead = head % maxItems;
        counterBuffer.counters.head = wrappedHead + 1;
        return wrappedHead;
    }
    
    return head;
}

bool hasWork() {
    return counterBuffer.counters.head != counterBuffer.counters.tail;
}

WorkItem dequeueWork() {
    uint index = atomicDequeue();
    return workQueueBuffer.workQueue.items[index];
}

void processRayTraversal(WorkItem item) {
    // Extract ray data
    vec3 origin = vec3(item.data[0], item.data[1], item.data[2]);
    vec3 direction = vec3(item.data[3], item.data[4], item.data[5]);
    uint pixelX = floatBitsToUint(item.data[6]);
    uint pixelY = floatBitsToUint(item.data[7]);
    
    // TODO: Call traversal function from traverse.comp
    // This would require shared function library or linking
    
    // For now, simple placeholder
    // vec4 result = traverseRay(origin, direction);
    // storeResult(pixelX, pixelY, result);
}

void processShadowRay(WorkItem item) {
    // Extract shadow ray data
    vec3 origin = vec3(item.data[0], item.data[1], item.data[2]);
    vec3 direction = vec3(item.data[3], item.data[4], item.data[5]);
    float maxDistance = item.data[6];
    uint lightIndex = floatBitsToUint(item.data[7]);
    
    // TODO: Call shadow traversal function
    // bool shadowed = traceShadowRay(origin, direction, maxDistance);
    // storeShadowResult(lightIndex, shadowed ? 1.0 : 0.0);
}

void processAmbientOcclusion(WorkItem item) {
    // Extract AO sample data
    vec3 position = vec3(item.data[0], item.data[1], item.data[2]);
    vec3 normal = vec3(item.data[3], item.data[4], item.data[5]);
    float radius = item.data[6];
    uint sampleIndex = floatBitsToUint(item.data[7]);
    
    // TODO: Generate AO sample ray and trace
    // vec3 sampleDir = generateAOSample(normal, sampleIndex);
    // bool occluded = traceAORay(position, sampleDir, radius);
    // storeAOResult(sampleIndex, occluded ? 0.0 : 1.0);
}

void processBeamTraversal(WorkItem item) {
    // Extract beam data
    // TODO: Implement beam traversal
}

void processWorkItem(WorkItem item) {
    switch (item.type) {
        case WORK_RAY_TRAVERSAL:
            processRayTraversal(item);
            break;
            
        case WORK_SHADOW_RAY:
            processShadowRay(item);
            break;
            
        case WORK_AMBIENT_OCCLUSION:
            processAmbientOcclusion(item);
            break;
            
        case WORK_BEAM_TRAVERSAL:
            processBeamTraversal(item);
            break;
            
        default:
            // Unknown work type
            break;
    }
}

void workGroupCoordination() {
    // Initialize shared memory
    if (threadId == 0) {
        sharedWorkAvailable = hasWork();
        sharedWorkCount = 0;
    }
    
    barrier();
    
    if (!sharedWorkAvailable) {
        return;
    }
    
    // Each thread tries to get work
    if (hasWork()) {
        uint workIndex = atomicAdd(sharedWorkCount, 1);
        if (workIndex < 32) {
            sharedWorkIndex[workIndex] = threadId;
        }
    }
    
    barrier();
    
    // Process assigned work
    uint assignedWork = sharedWorkCount;
    if (threadId < assignedWork) {
        uint workerThread = sharedWorkIndex[threadId];
        if (workerThread == threadId && hasWork()) {
            WorkItem work = dequeueWork();
            processWorkItem(work);
        }
    }
}

void individualWork() {
    // Simple individual work processing
    while (hasWork()) {
        WorkItem work = dequeueWork();
        processWorkItem(work);
        
        // Prevent infinite loops
        if (gl_GlobalInvocationID.x % 1000 == 0) {
            break;
        }
    }
}

void main() {
    // Check if this thread should be active
    // For persistent threads, we want to keep looping
    
    #ifdef ENABLE_WORKGROUP_COORDINATION
        workGroupCoordination();
    #else
        individualWork();
    #endif
    
    // For persistent operation, threads would continue in a loop
    // This requires careful synchronization and termination conditions
    
    #ifdef PERSISTENT_MODE
        // Persistent thread loop
        uint iterations = 0;
        const uint maxIterations = 10000; // Prevent runaway
        
        while (iterations < maxIterations) {
            if (hasWork()) {
                WorkItem work = dequeueWork();
                processWorkItem(work);
            } else {
                // No work available, yield or wait
                // In real GPU, this might be a sleep or yield instruction
                break;
            }
            
            iterations++;
        }
    #endif
    
    // Update statistics
    #ifdef ENABLE_STATISTICS
        if (threadId == 0) {
            // Update block-level statistics
            atomicAdd(counterBuffer.counters.currentSize, 
                     -int(sharedWorkCount));
        }
    #endif
}