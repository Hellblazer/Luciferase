# Sentry Performance Benchmark Framework

## Overview

This document outlines a comprehensive benchmarking framework for measuring and validating performance optimizations in the Sentry module.

## Benchmark Suite Design

### 1. Micro-Benchmarks

#### Geometric Predicate Benchmarks
```java
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.NANOSECONDS)
@State(Scope.Thread)
public class GeometricPredicateBenchmark {
    
    private double[] coords;
    
    @Setup
    public void setup() {
        // Generate random coordinates
        coords = new double[12];
        Random r = new Random(42);
        for (int i = 0; i < 12; i++) {
            coords[i] = r.nextDouble() * 1000;
        }
    }
    
    @Benchmark
    public double testLeftOfPlaneFast() {
        return Geometry.leftOfPlaneFast(
            coords[0], coords[1], coords[2],
            coords[3], coords[4], coords[5],
            coords[6], coords[7], coords[8],
            coords[9], coords[10], coords[11]
        );
    }
    
    @Benchmark
    public double testLeftOfPlaneFMA() {
        return Geometry.leftOfPlaneFMA(
            coords[0], coords[1], coords[2],
            coords[3], coords[4], coords[5],
            coords[6], coords[7], coords[8],
            coords[9], coords[10], coords[11]
        );
    }
}
```

#### Data Structure Benchmarks
```java
@State(Scope.Thread)
public class DataStructureBenchmark {
    
    private LinkedList<OrientedFace> linkedList;
    private ArrayList<OrientedFace> arrayList;
    private static final int SIZE = 100;
    
    @Setup
    public void setup() {
        linkedList = new LinkedList<>();
        arrayList = new ArrayList<>(SIZE);
        
        for (int i = 0; i < SIZE; i++) {
            OrientedFace face = createRandomFace();
            linkedList.add(face);
            arrayList.add(face);
        }
    }
    
    @Benchmark
    public OrientedFace linkedListAccess() {
        OrientedFace result = null;
        for (int i = 0; i < SIZE; i++) {
            result = linkedList.get(i);
        }
        return result;
    }
    
    @Benchmark
    public OrientedFace arrayListAccess() {
        OrientedFace result = null;
        for (int i = 0; i < SIZE; i++) {
            result = arrayList.get(i);
        }
        return result;
    }
}
```

### 2. Component Benchmarks

#### Flip Operation Benchmark
```java
@State(Scope.Thread)
public class FlipBenchmark {
    
    private MutableGrid grid;
    private List<Vertex> vertices;
    
    @Setup(Level.Trial)
    public void setup() {
        grid = new MutableGrid();
        vertices = generateRandomVertices(1000);
        
        // Build initial tetrahedralization
        for (Vertex v : vertices) {
            grid.add(v);
        }
    }
    
    @Benchmark
    @BenchmarkMode(Mode.Throughput)
    public void benchmarkFlipOperations() {
        // Delete and re-add vertices to trigger flips
        Vertex v = vertices.get(ThreadLocalRandom.current().nextInt(vertices.size()));
        grid.delete(v);
        grid.add(v);
    }
}
```

### 3. End-to-End Benchmarks

#### Complete Tetrahedralization Benchmark
```java
public class TetrahedralizationBenchmark {
    
    @Param({"100", "1000", "10000", "100000"})
    private int pointCount;
    
    @Param({"RANDOM", "GRID", "SPHERE", "CLUSTERED"})
    private PointDistribution distribution;
    
    private List<Point3f> points;
    
    @Setup
    public void setup() {
        points = generatePoints(pointCount, distribution);
    }
    
    @Benchmark
    public MutableGrid benchmarkIncremental() {
        MutableGrid grid = new MutableGrid();
        for (Point3f p : points) {
            grid.add(new Vertex(p));
        }
        return grid;
    }
}
```

## Performance Metrics

### 1. Primary Metrics
- **Throughput**: Operations per second
- **Latency**: Time per operation (avg, p50, p95, p99)
- **Memory Usage**: Heap allocation rate, GC pressure
- **Cache Performance**: L1/L2/L3 miss rates

### 2. Secondary Metrics
- **Branch Prediction**: Misprediction rate
- **CPU Utilization**: Core usage patterns
- **Memory Bandwidth**: GB/s utilized
- **Instruction Count**: Instructions per operation

## Measurement Tools

### 1. JMH Configuration
```xml
<dependency>
    <groupId>org.openjdk.jmh</groupId>
    <artifactId>jmh-core</artifactId>
    <version>1.36</version>
</dependency>

<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-shade-plugin</artifactId>
    <configuration>
        <transformers>
            <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                <mainClass>org.openjdk.jmh.Main</mainClass>
            </transformer>
        </transformers>
    </configuration>
</plugin>
```

### 2. Profiling Integration
```java
public class ProfiledBenchmark {
    
    @Fork(jvmArgs = {
        "-XX:+UnlockDiagnosticVMOptions",
        "-XX:+PrintInlining",
        "-XX:+PrintCompilation",
        "-XX:+LogCompilation",
        "-XX:LogFile=compilation.log"
    })
    @Benchmark
    public void profiledOperation() {
        // Operation to profile
    }
}
```

### 3. Performance Monitoring
```java
public class PerformanceMonitor {
    
    private final MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
    
    public void collectMetrics() {
        // CPU usage
        OperatingSystemMXBean osBean = ManagementFactory.getOperatingSystemMXBean();
        double cpuUsage = osBean.getProcessCpuLoad();
        
        // Memory usage
        MemoryMXBean memBean = ManagementFactory.getMemoryMXBean();
        MemoryUsage heapUsage = memBean.getHeapMemoryUsage();
        
        // GC statistics
        List<GarbageCollectorMXBean> gcBeans = ManagementFactory.getGarbageCollectorMXBeans();
        for (GarbageCollectorMXBean gc : gcBeans) {
            long count = gc.getCollectionCount();
            long time = gc.getCollectionTime();
        }
    }
}
```

## Validation Framework

### 1. Correctness Validation
```java
public class CorrectnessValidator {
    
    @Test
    public void validateDelaunayProperty() {
        MutableGrid grid = createTestGrid();
        
        for (Tetrahedron tet : grid.tetrahedra()) {
            for (Vertex v : grid.vertices()) {
                if (!tet.contains(v)) {
                    assertFalse("Delaunay violation", 
                        tet.inSphere(v));
                }
            }
        }
    }
    
    @Test
    public void validateTopology() {
        MutableGrid grid = createTestGrid();
        
        for (Tetrahedron tet : grid.tetrahedra()) {
            // Verify neighbor relationships are symmetric
            for (V face : V.values()) {
                Tetrahedron neighbor = tet.getNeighbor(face);
                if (neighbor != null) {
                    assertEquals(tet, 
                        neighbor.getNeighbor(neighbor.ordinalOf(tet)));
                }
            }
        }
    }
}
```

### 2. Performance Regression Detection
```java
public class RegressionDetector {
    
    private static final double REGRESSION_THRESHOLD = 1.05; // 5% regression
    
    public void checkRegression(BenchmarkResult baseline, BenchmarkResult current) {
        double baselineScore = baseline.getScore();
        double currentScore = current.getScore();
        
        if (currentScore > baselineScore * REGRESSION_THRESHOLD) {
            throw new PerformanceRegressionException(
                String.format("Performance regression detected: %.2f%% slower",
                    (currentScore / baselineScore - 1) * 100)
            );
        }
    }
}
```

## Benchmark Execution Pipeline

### 1. Automated Benchmark Suite
```bash
#!/bin/bash
# run-benchmarks.sh

# Warmup system
java -jar warmup.jar

# Run micro-benchmarks
java -jar jmh-benchmarks.jar \
    -f 3 \
    -wi 10 -w 1s \
    -i 10 -r 1s \
    -rf json -rff results/micro.json \
    ".*Micro.*"

# Run component benchmarks
java -jar jmh-benchmarks.jar \
    -f 1 \
    -wi 5 -w 5s \
    -i 5 -r 5s \
    -rf json -rff results/component.json \
    ".*Component.*"

# Run end-to-end benchmarks
java -jar jmh-benchmarks.jar \
    -f 1 \
    -wi 3 -w 10s \
    -i 3 -r 30s \
    -rf json -rff results/e2e.json \
    ".*E2E.*"
```

### 2. Result Analysis
```java
public class BenchmarkAnalyzer {
    
    public void analyzResults(String jsonFile) {
        List<BenchmarkResult> results = parseResults(jsonFile);
        
        // Statistical analysis
        for (BenchmarkResult result : results) {
            System.out.printf("%s: %.2f Â± %.2f %s%n",
                result.getBenchmark(),
                result.getScore(),
                result.getScoreError(),
                result.getScoreUnit()
            );
        }
        
        // Comparison with baseline
        compareWithBaseline(results);
        
        // Generate report
        generateHTMLReport(results);
    }
}
```

## Continuous Performance Testing

### 1. CI Integration
```yaml
# .github/workflows/performance.yml
name: Performance Tests

on:
  pull_request:
    paths:
      - 'sentry/**'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup JDK
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          
      - name: Run Benchmarks
        run: mvn clean verify -P benchmark
        
      - name: Compare with Baseline
        run: |
          java -cp target/benchmarks.jar \
            com.hellblazer.sentry.bench.RegressionDetector \
            baseline.json \
            target/benchmark-results.json
            
      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: target/benchmark-results.json
```

### 2. Performance Dashboard
```java
@RestController
public class PerformanceDashboard {
    
    @GetMapping("/api/performance/trends")
    public List<PerformanceTrend> getTrends() {
        // Return historical performance data
    }
    
    @GetMapping("/api/performance/comparison")
    public ComparisonResult compare(
            @RequestParam String baseline,
            @RequestParam String current) {
        // Compare two benchmark runs
    }
}
```

## Best Practices

1. **Warm-up**: Always include sufficient warm-up iterations
2. **Isolation**: Run benchmarks on isolated hardware
3. **Repeatability**: Use fixed seeds for random data
4. **Statistical Significance**: Run multiple forks and iterations
5. **Version Control**: Track benchmark code with main code
6. **Documentation**: Document benchmark assumptions and setup